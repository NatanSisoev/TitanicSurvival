{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZMnmdDBCl7F"
      },
      "source": [
        "# Pr√†ctica 1: Resolem un problema de classificaci√≥\n",
        "\n",
        "## Objectius\n",
        "\n",
        "Els objectius d'aquesta pr√†ctica s√≥n:\n",
        "\n",
        "* Aplicar els coneixements adquirits sobre processament de dades, classificaci√≥ i validacio creuada.\n",
        "  \n",
        "* Ser capa√ß de comparar diferents models de classificaci√≥.\n",
        "\n",
        "* Ser capac de fer cerca d'hiperpar√†metres.\n",
        "\n",
        "* Entendre i implementar la validaci√≥ creuada.\n",
        "\n",
        "* Analitzar detalladament els resultats obtinguts durant l'aprenentatge dels diferents models.\n",
        "\n",
        "Aquesta pr√†ctica √©s pr√®via al cas kaggle que realitzareu durant la segona part de l'assignatura. En aquesta primera pr√†ctica les preguntes estan definides, per√≤ us ha de servir d'aprenentatge a l'hora de saber com estructurar un projecte d'aprenentatge autom√†tic ja que en el cas kaggle no tindreu les preguntes.\n",
        "\n",
        "## Base de dades\n",
        "\n",
        "En aquesta pr√†ctica farem servir la base de dades del titanic. L'atribut que predirem es Survived, el qual ens diu si cada passatger va sobreviure o no.\n",
        "\n",
        "\n",
        "https://www.kaggle.com/c/titanic/data\n",
        "\n",
        "\n",
        "## Treball en grup\n",
        "Aquesta pr√†ctica es treballar√† en grups de 2-3 persones. En casos excepcionals i degudament justificats la pr√†ctica es podr√† realitzar de forma individual.\n",
        "\n",
        "## Seguiment i entrega de la pr√†ctica\n",
        "\n",
        "En la pr√†ctica 1 es presenten diverses tasques per fer una correcta comparativa dels resultats obtinguts per diversos m√®todes de classificaci√≥ en una mateixa base de dades.\n",
        "\n",
        "En aquesta pr√†ctica es realitzaran sessions de seguiment del treball. Aquestes sessions de treball estan orientades a que els alumnes que vingueu pugueu preguntar i resoldre dubtes sobre les dades, preguntar sobre l'objectiu de cada apartat dels enunciats que no us hagi quedat clar, i preguntar sobre els resultats que esteu obtenint a l'hora d'analitzar les dades. √âs molt recomanable venir a classe amb el treball fet per tal de poder comentar dubtes.\n",
        "\n",
        "Pel que fa l'entrega, caldr√† entregar per caronte el seg√ºent:\n",
        "\n",
        "1. Mem√≤ria en format PDF explicant els resultats trobats sobre la bases de dades. La mem√≤ria ha d'utilitzar la plantilla de LaTeX que podeu trobar al Caronte i ha de ser de com a m√†xim 3 p√†gines.\n",
        "   \n",
        "2. Notebook amb el respectiu codi de python.\n",
        "\n",
        "3. (Opcional) Presentaci√≥ amb els resultats 4 min m√†xim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zdgsxfuCl7S"
      },
      "source": [
        "# Descripci√≥ de la pr√†ctica\n",
        "\n",
        "A continuaci√≥ es mostren tots els continguts que s'evaluaran en la pr√†ctica:\n",
        "\n",
        "1. EDA (exploratory data analysis) (1 punt):\n",
        "  * An√†lisi de tamany i tipologia de dades\n",
        "  * Primera valoraci√≥ de correlacions\n",
        "  * An√†lisi atribut target\n",
        "2. Preprocessing (2 punts):\n",
        "  * Eliminaci√≥ de nans\n",
        "  * Encoding de categ√≤riques\n",
        "  * Altres (PCA, normalitzaci√≥, ...)\n",
        "3. Metric selection (1.5 punts):\n",
        "  * Selecci√≥ de la millor m√®trica pel problema\n",
        "  * Visualitzaci√≥ de ROC/AUC per model base\n",
        "4. Model Selection amb Crossvalidation (4 punts):\n",
        "  * Selecci√≥ del millor model\n",
        "  * Cerca d'hiperpar√†metres\n",
        "5. An√†lisi final (1.5 punt)\n",
        "\n",
        "La pr√†ctica esta construida a partir d'un seguit de preguntes orientatives en cada apartat les quals tenen relaci√≥ amb els continguts evaluables. **NO cal contestar-les totes**. S√≥n una guia per a que reflexioneu i aprengueu detalls de cada apartat. √âs recomanable llegir totes les preguntes abans de realitzar la pr√†ctica i tenir-les en ment a l'hora d'executar-la.\n",
        "\n",
        "\n",
        "**IMPORTANT**: El que es valorar√† en la pr√†ctica √©s la capacitat de mantenir una narrativa coherent alhora que s'expliquen els resultats. No es mirar√† tant que alguna pregunta quedi per respondre sin√≥ que els passos seguits en base als resultats obtinguts siguin coherents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuENGdYFCl7S"
      },
      "source": [
        "### 1. EDA (exploratory data analysis) (1 punt)\n",
        "\n",
        "Abans de res cal sempre veure com es la base de dades assignada.\n",
        "\n",
        "**Preguntes:**\n",
        "* Quants atributs t√© la vostra base de dades?\n",
        "* Quin tipus d'atributs teniu? (N√∫merics, temporals, categ√≤rics, binaris...)\n",
        "* Com es el target? quantes categories diferents existeixen?\n",
        "* Tenim nans en les dades?\n",
        "* Podeu veure alguna correlaci√≥ entre X i y?\n",
        "* Estan balancejades les etiquetes (distribuci√≥ similar entre categories)? Creieu que pot afectar a la classificaci√≥ la seva distribuci√≥?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre d'atributs: 12\n",
            "\n",
            "Tipus d'atributs:\n",
            " PassengerId      int64\n",
            "Survived         int64\n",
            "Pclass           int64\n",
            "Name            object\n",
            "Sex             object\n",
            "Age            float64\n",
            "SibSp            int64\n",
            "Parch            int64\n",
            "Ticket          object\n",
            "Fare           float64\n",
            "Cabin           object\n",
            "Embarked        object\n",
            "dtype: object\n",
            "\n",
            "Target: Survived\n",
            "   Nombre de categories: 2\n",
            "   Categories existents: [0 1]\n",
            "\n",
            "Nombre de NaNs per columna:\n",
            " PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "\n",
            "Correlaci√≥ de cada atribut num√®ric amb el target:\n",
            " Survived       1.000000\n",
            "Fare           0.257307\n",
            "Parch          0.081629\n",
            "PassengerId   -0.005007\n",
            "SibSp         -0.035322\n",
            "Age           -0.077221\n",
            "Pclass        -0.338481\n",
            "Name: Survived, dtype: float64\n",
            "\n",
            "Distribuci√≥ de les etiquetes (proporci√≥):\n",
            " Survived\n",
            "0    0.616162\n",
            "1    0.383838\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Carregar el dataset\n",
        "df = pd.read_csv(\"./titanic/train.csv\")\n",
        "\n",
        "# 1Ô∏è‚É£ Quants atributs t√© la base de dades?\n",
        "num_atributs = df.shape[1]\n",
        "print(\"Nombre d'atributs:\", num_atributs)\n",
        "\n",
        "# 2Ô∏è‚É£ Tipus d'atributs\n",
        "tipus_atributs = df.dtypes\n",
        "print(\"\\nTipus d'atributs:\\n\", tipus_atributs)\n",
        "\n",
        "# 3Ô∏è‚É£ Target i categories\n",
        "target = 'Survived'\n",
        "categories_target = df[target].nunique()\n",
        "print(\"\\nTarget:\", target)\n",
        "print(\"   Nombre de categories:\", categories_target)\n",
        "print(\"   Categories existents:\", df[target].unique())\n",
        "\n",
        "# 4Ô∏è‚É£ NaNs en les dades\n",
        "nans = df.isna().sum()\n",
        "print(\"\\nNombre de NaNs per columna:\\n\", nans)\n",
        "\n",
        "# 5Ô∏è‚É£ Correlaci√≥ entre atributs num√®rics i target\n",
        "# Seleccionar nom√©s columnes num√®riques\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Correlaci√≥ nom√©s amb num√®rics\n",
        "correlacions = df[num_cols].corr()[target].sort_values(ascending=False)\n",
        "print(\"\\nCorrelaci√≥ de cada atribut num√®ric amb el target:\\n\", correlacions)\n",
        "\n",
        "# 6Ô∏è‚É£ Distribuci√≥ de les etiquetes\n",
        "distribucio_target = df[target].value_counts(normalize=True)\n",
        "print(\"\\nDistribuci√≥ de les etiquetes (proporci√≥):\\n\", distribucio_target)\n",
        "\n",
        "# Observaci√≥ de l'impacte: es pot veure que no est√† balancejat\n",
        "if distribucio_target.min() / distribucio_target.max() < 0.5:\n",
        "    print(\"   ‚ö†Ô∏è Les etiquetes no estan balancejades, pot afectar la classificaci√≥\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuLtWQWpCl7T"
      },
      "source": [
        "### 2. Preprocessing (normalitzation, outlier removal, feature selection, ...) (2 punts)\n",
        "Un cop vistes les dades de les que es disposa, cal preparar les dades per als nostres algoritmes. Segons la tipologia de dades, es poden filtrar atributs, aplicar-hi reductors de dimensionalitat, codificar categories textuals en valors num√®rics, normalitzar les dades, treure outliers...\n",
        "\n",
        "Navegueu per la [documentaci√≥ de sklearn sobre preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) per tal de trobar les diferents opcions que proporciona sklearn.\n",
        "\n",
        "**Preguntes:**\n",
        "* Estan les dades normalitzades? Caldria fer-ho?\n",
        "* En cas que les normalitzeu, quin tipus de normalitzaci√≥ ser√† m√©s adient per a les vostres dades?\n",
        "* Teniu gaires dades sense informaci√≥ (nans)? Tingueu en compte que hi ha metodes que no els toleren durant l'aprenentatge. Com afecta a la classificaci√≥ si les filtrem? I si les reompliu? Com ho farieu? [Pista](https://scikit-learn.org/stable/modules/impute.html)\n",
        "* Teniu dades categ√≤riques? Quina seria la codificaci√≥ amb m√©s sentit?\n",
        "* Podreu treure algun atribut extra de les categ√≤riques (per exemple, aplicant alguna regla sobre el text)?\n",
        "* Caldria aplicar PCA? Quins beneficis o inconvenients trobarieu?\n",
        "* Caldria aplicar alguna t√®cnica de selecci√≥ de variables? Ho trobeu necessari?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "APARTAT 2: PREPROCESSING\n",
            "================================================================================\n",
            "\n",
            "üìä 2.1 AN√ÄLISI DE VALORS FALTANTS\n",
            "----------------------------------------\n",
            "          Total_NaN  Percentatge\n",
            "Age             177        19.87\n",
            "Cabin           687        77.10\n",
            "Embarked          2         0.22\n",
            "\n",
            "‚ö†Ô∏è  ESTRAT√àGIA DE TRACTAMENT DE NaNs:\n",
            "\n",
            "1. Age (19.87% NaNs):\n",
            "   ‚Üí Estrat√®gia: KNNImputer amb k=5\n",
            "   ‚Üí Justificaci√≥: L'edat √©s una variable cr√≠tica per la superviv√®ncia.\n",
            "     KNNImputer utilitza la informaci√≥ multivariable (Sex, Pclass, Fare, etc.)\n",
            "     per estimar valors m√©s realistes que una simple mitjana.\n",
            "     Mantenim la variabilitat natural i les relacions amb altres variables.\n",
            "\n",
            "2. Cabin (77.10% NaNs):\n",
            "   ‚Üí Estrat√®gia: Crear variable bin√†ria 'Cabin_known' + eliminar columna original\n",
            "   ‚Üí Justificaci√≥: Massa NaNs per imputar de manera fiable.\n",
            "     Tenir cabina coneguda pot indicar classe social o proximitat a les sortides.\n",
            "     La informaci√≥ bin√†ria (t√©/no t√© cabina) √©s m√©s √∫til que la cabina espec√≠fica.\n",
            "\n",
            "3. Embarked (0.22% NaNs):\n",
            "   ‚Üí Estrat√®gia: SimpleImputer amb strategy='most_frequent'\n",
            "   ‚Üí Justificaci√≥: Percentatge m√≠nim de NaNs. La moda √©s suficient i no\n",
            "     distorsiona la distribuci√≥. √âs eficient i mant√© la consist√®ncia.\n",
            "\n",
            "üîç ALTERNATIVES CONSIDERADES I DESCARTADES:\n",
            "\n",
            "‚Ä¢ SimpleImputer (mean/median/mode):\n",
            "  ‚úó Per Age: No considera relacions amb altres variables (Sex, Pclass, etc.)\n",
            "  ‚úì Per Embarked: Adequat pel baix % de NaNs\n",
            "\n",
            "‚Ä¢ IterativeImputer (MICE):\n",
            "  ‚úó Massa computacionalment cost√≥s per aquest dataset\n",
            "  ‚úó Risc de sobreajust amb poques dades\n",
            "  ‚úó KNNImputer ja captura relacions multivariables de forma m√©s simple\n",
            "\n",
            "‚Ä¢ Eliminar files amb NaNs:\n",
            "  ‚úó Perdr√≠em ~20% del dataset (177 passatgers)\n",
            "  ‚úó P√®rdua significativa d'informaci√≥ per entrenar el model\n",
            "\n",
            "‚Ä¢ MissingIndicator:\n",
            "  ‚úó Redundant: ja creem 'Cabin_known' per capturar aquesta informaci√≥\n",
            "\n",
            "‚úì CONCLUSI√ì: KNNImputer per Age + Cabin_known + most_frequent per Embarked\n",
            "\n",
            "üîß 2.2 FEATURE ENGINEERING\n",
            "----------------------------------------\n",
            "\n",
            "üìå 2.2.1 EXTRACCI√ì DE T√çTOL DEL NOM\n",
            "T√≠tols √∫nics trobats: 17\n",
            "\n",
            "Distribuci√≥ original de t√≠tols:\n",
            "Title\n",
            "Mr          517\n",
            "Miss        182\n",
            "Mrs         125\n",
            "Master       40\n",
            "Dr            7\n",
            "Rev           6\n",
            "Col           2\n",
            "Mlle          2\n",
            "Major         2\n",
            "Ms            1\n",
            "Mme           1\n",
            "Don           1\n",
            "Lady          1\n",
            "Sir           1\n",
            "Capt          1\n",
            "Countess      1\n",
            "Jonkheer      1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "‚úì T√≠tols agrupats:\n",
            "Title\n",
            "Mr         517\n",
            "Miss       185\n",
            "Mrs        128\n",
            "Master      40\n",
            "Officer     21\n",
            "Name: count, dtype: int64\n",
            "\n",
            "L√≤gica d'agrupaci√≥:\n",
            "  ‚Ä¢ Miss: Dones joves/solteres (Miss, Mlle, Ms)\n",
            "  ‚Ä¢ Mrs: Dones casades/classe alta (Mrs, Mme, Lady, Countess, Dona)\n",
            "  ‚Ä¢ Officer: Homes amb t√≠tols oficials/militars/aristocr√†tics\n",
            "  ‚Ä¢ Mr, Master: Mantinguts per alta freq√º√®ncia i rellev√†ncia\n",
            "\n",
            "üìå 2.2.2 CREACI√ì DE CABIN_KNOWN\n",
            "‚úì 204 passatgers (22.90%) amb cabina coneguda\n",
            "   Justificaci√≥: Tenir cabina pot correlacionar amb classe social i superviv√®ncia\n",
            "\n",
            "üìå 2.2.3 CREACI√ì DE FAMILY_SIZE\n",
            "‚úì Rang de Family_size: [1, 11]\n",
            "   Distribuci√≥: {1: 537, 2: 161, 3: 102, 4: 29, 5: 15, 6: 22, 7: 12, 8: 6, 11: 7}\n",
            "   Justificaci√≥: Fam√≠lies grans poden tenir m√©s dificultat per evacuar\n",
            "\n",
            "üìå 2.2.4 CREACI√ì DE IS_ALONE\n",
            "‚úì 537 passatgers (60.27%) viatjant sols\n",
            "   Justificaci√≥: Viatjar sol pot afectar les possibilitats de superviv√®ncia\n",
            "\n",
            "üìå 2.2.5 SELECCI√ì DE FEATURES - AN√ÄLISI\n",
            "\n",
            "üîç ENFOCAMENT: Mantenir totes les variables (excepte les eliminades expl√≠citament)\n",
            "\n",
            "RAONAMENT:\n",
            "  ‚Ä¢ En ML no necessitem causalitat, sin√≥ CORRELACI√ì/ASSOCIACI√ì\n",
            "  ‚Ä¢ Prioritzem ACCURACY sobre efici√®ncia computacional\n",
            "  ‚Ä¢ Sense con√®ixer la naturalesa exacta de totes les dades, √©s arriscat eliminar-les\n",
            "\n",
            "‚úì Variables mantingudes: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked,\n",
            "                          Title, Cabin_known, Family_size, Is_alone\n",
            "\n",
            "‚úó Variables eliminades: PassengerId (identificador √∫nic sense valor predictiu)\n",
            "                        Name (informaci√≥ extreta en 'Title')\n",
            "                        Ticket (format inconsistent, dif√≠cil d'interpretar)\n",
            "                        Cabin (substitu√Øda per 'Cabin_known')\n",
            "\n",
            "üìä T√àCNIQUES DE SELECCI√ì CONSIDERADES:\n",
            "\n",
            "‚Ä¢ Mutual Information: Relaci√≥ general entre features i target\n",
            "‚Ä¢ Chi-quadrat / Cram√©r's V: Per variables categ√≤riques\n",
            "‚Ä¢ Point-biserial correlation: Per variables bin√†ries\n",
            "‚Ä¢ Spearman correlation: Per variables ordinals\n",
            "\n",
            "‚ö†Ô∏è  NO APLICADES en aquesta fase perqu√®:\n",
            "   1. Alguns models (Random Forest, XGBoost) fan selecci√≥ impl√≠cita\n",
            "   2. Volem comparar el rendiment amb/sense totes les features\n",
            "   3. El cost computacional √©s acceptable amb aquest dataset\n",
            "\n",
            "üí° MILLORA FUTURA:\n",
            "   Avaluar la import√†ncia de cada feature en el model final (feature_importances_)\n",
            "   i eliminar aquelles amb contribuci√≥ m√≠nima, comparant l'accuracy resultant.\n",
            "\n",
            "üóëÔ∏è  2.3 ELIMINACI√ì DE COLUMNES IRRELLEVANTS\n",
            "----------------------------------------\n",
            "Columnes eliminades: ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
            "\n",
            "Justificacions:\n",
            "  ‚Ä¢ PassengerId: Identificador √∫nic sense valor predictiu\n",
            "  ‚Ä¢ Name: Informaci√≥ extreta en 'Title'\n",
            "  ‚Ä¢ Ticket: Format inconsistent i dif√≠cil d'interpretar\n",
            "  ‚Ä¢ Cabin: Substitu√Øda per 'Cabin_known'\n",
            "\n",
            "‚úì Dataset resultant: (891, 12)\n",
            "\n",
            "üéØ 2.4 SEPARACI√ì DE FEATURES I TARGET\n",
            "----------------------------------------\n",
            "‚úì Features (X): (891, 11)\n",
            "‚úì Target (y): (891,)\n",
            "\n",
            "‚úì Distribuci√≥ del target:\n",
            "   Classe 0: 61.62%\n",
            "   Classe 1: 38.38%\n",
            "\n",
            "üìã 2.5 IDENTIFICACI√ì DE TIPUS DE VARIABLES\n",
            "----------------------------------------\n",
            "\n",
            "üìä Variables num√®riques (5):\n",
            "   ['Age', 'Fare', 'SibSp', 'Parch', 'Family_size']\n",
            "\n",
            "üè∑Ô∏è  Variables categ√≤riques (4):\n",
            "   ['Pclass', 'Sex', 'Embarked', 'Title']\n",
            "\n",
            "‚ö´‚ö™ Variables bin√†ries (2):\n",
            "   ['Cabin_known', 'Is_alone']\n",
            "\n",
            "üí° ESTRAT√àGIA DE CODIFICACI√ì:\n",
            "  ‚Ä¢ Num√®riques: StandardScaler (despr√©s de imputar NaNs)\n",
            "  ‚Ä¢ Categ√≤riques: OneHotEncoder amb drop='first' (evitar multicolinearitat)\n",
            "  ‚Ä¢ Bin√†ries: Sense transformaci√≥ (ja s√≥n 0/1)\n",
            "\n",
            "üìê 2.6 AN√ÄLISI DE NORMALITZACI√ì\n",
            "----------------------------------------\n",
            "\n",
            "‚ùì ESTAN LES DADES NORMALITZADES?\n",
            "\n",
            "Estad√≠stiques ABANS de normalitzar:\n",
            "            Age        Fare     SibSp     Parch  Family_size\n",
            "mean  29.699118   32.204208  0.523008  0.381594     1.904602\n",
            "std   14.526497   49.693429  1.102743  0.806057     1.613459\n",
            "min    0.420000    0.000000  0.000000  0.000000     1.000000\n",
            "max   80.000000  512.329200  8.000000  6.000000    11.000000\n",
            "\n",
            "‚ùå NO estan normalitzades:\n",
            "   ‚Ä¢ Age: rang [0.42, 80] amb mean‚âà29.7\n",
            "   ‚Ä¢ Fare: rang [0, 512] amb mean‚âà32.2\n",
            "   ‚Ä¢ Les escales s√≥n molt diferents ‚Üí Afecta models basats en dist√†ncies\n",
            "\n",
            "‚úÖ CALDRIA NORMALITZAR-LES?\n",
            "\n",
            "   S√ç, pels seg√ºents motius:\n",
            "   1. Models sensibles a escales (KNN, SVM, Regressi√≥ Log√≠stica):\n",
            "      ‚Üí Fare (0-512) dominaria sobre Age (0-80) en c√†lculs de dist√†ncia\n",
            "   2. Millora la converg√®ncia de gradient descent\n",
            "   3. Facilita la interpretaci√≥ de coeficients en models lineals\n",
            "   4. StandardScaler √©s robust a outliers moderats\n",
            "\n",
            "üîß TIPUS DE NORMALITZACI√ì ESCOLLIDA: StandardScaler\n",
            "\n",
            "   F√≥rmula: z = (x - Œº) / œÉ\n",
            "   ‚Ä¢ Transforma a mitjana=0 i std=1\n",
            "   ‚Ä¢ Mant√©n la distribuci√≥ original\n",
            "   ‚Ä¢ No afectat per outliers extrems (a difer√®ncia de MinMaxScaler)\n",
            "\n",
            "   Alternatives considerades:\n",
            "   ‚Ä¢ MinMaxScaler: ‚úó Sensible a outliers (Fare t√© valors extrems)\n",
            "   ‚Ä¢ RobustScaler: ‚úì Alternativa v√†lida, per√≤ StandardScaler √©s suficient\n",
            "   ‚Ä¢ Normalizer: ‚úó Normalitza per files, no per columnes (no aplica aqu√≠)\n",
            "\n",
            "üî¨ 2.7 CALDRIA APLICAR PCA?\n",
            "----------------------------------------\n",
            "\n",
            "‚ùå NO aplicarem PCA en aquest cas\n",
            "\n",
            "RAONS:\n",
            "  ‚Ä¢ Dataset petit (891 passatgers, ~15 features despr√©s de OneHot)\n",
            "  ‚Ä¢ No hi ha problema de dimensionalitat (regla general: n_samples >> n_features)\n",
            "  ‚Ä¢ P√®rdua d'interpretabilitat: no sabr√≠em quines features s√≥n importants\n",
            "  ‚Ä¢ Les features tenen significat real i volem mantenir-lo\n",
            "\n",
            "‚úÖ BENEFICIS de PCA (si s'apliqu√©s):\n",
            "  + Reducci√≥ de dimensionalitat\n",
            "  + Eliminaci√≥ de multicolinearitat\n",
            "  + Reducci√≥ de soroll\n",
            "  + Millora computacional en datasets grans\n",
            "\n",
            "‚ùå INCONVENIENTS de PCA:\n",
            "  - P√®rdua d'interpretabilitat (components principals no tenen significat clar)\n",
            "  - Assumeix relacions lineals\n",
            "  - Requereix normalitzaci√≥ pr√®via\n",
            "  - Pot eliminar informaci√≥ rellevant per models no lineals\n",
            "\n",
            "üí° CONCLUSI√ì: Mantenim les features originals per interpretabilitat i\n",
            "              perqu√® el dataset no t√© problemes de dimensionalitat.\n",
            "\n",
            "üîÑ 2.8 CREACI√ì DEL PIPELINE DE PREPROCESSING\n",
            "----------------------------------------\n",
            "‚úì Pipeline creat amb 3 components:\n",
            "\n",
            "  1Ô∏è‚É£  NUM√àRIQUES:\n",
            "      ‚Üí KNNImputer(n_neighbors=5): Imputa Age basant-se en 5 ve√Øns m√©s propers\n",
            "      ‚Üí StandardScaler(): Normalitza a mean=0, std=1\n",
            "      ‚Üí Aplica a: ['Age', 'Fare', 'SibSp', 'Parch', 'Family_size']\n",
            "\n",
            "  2Ô∏è‚É£  CATEG√íRIQUES:\n",
            "      ‚Üí SimpleImputer(most_frequent): Imputa Embarked amb la moda\n",
            "      ‚Üí OneHotEncoder(drop='first'): Evita dummy variable trap\n",
            "      ‚Üí Aplica a: ['Pclass', 'Sex', 'Embarked', 'Title']\n",
            "\n",
            "  3Ô∏è‚É£  BIN√ÄRIES:\n",
            "      ‚Üí Passthrough: No es transformen (ja s√≥n 0/1)\n",
            "      ‚Üí Aplica a: ['Cabin_known', 'Is_alone']\n",
            "\n",
            "‚öôÔ∏è  2.9 TRAIN/TEST SPLIT I APLICACI√ì DEL PREPROCESSING\n",
            "----------------------------------------\n",
            "‚úì Train set: (712, 11) (79.9%)\n",
            "‚úì Test set:  (179, 11) (20.1%)\n",
            "\n",
            "‚úì Distribuci√≥ mantinguda (stratify=y):\n",
            "   Classe 0: Train=61.66%, Test=61.45%\n",
            "   Classe 1: Train=38.34%, Test=38.55%\n",
            "\n",
            "üîß Aplicant preprocessing...\n",
            "\n",
            "‚úì Dades preprocessades:\n",
            "   Train shape: (712, 16)\n",
            "   Test shape:  (179, 16)\n",
            "   Total features: 16\n",
            "\n",
            "‚úÖ VERIFICACI√ì DE NORMALITZACI√ì (primeres 5 columnes num√®riques):\n",
            "   Mitjana:     -0.000000 (esperat: ‚âà0)\n",
            "   Desv. std:   1.000000 (esperat: ‚âà1)\n",
            "   Min:         -2.21\n",
            "   Max:         10.01\n",
            "\n",
            "   ‚úì Normalitzaci√≥ correcta!\n",
            "\n",
            "================================================================================\n",
            "üìù RESUM DEL PREPROCESSING\n",
            "================================================================================\n",
            "\n",
            "‚úÖ DECISIONS PRESES:\n",
            "   1. NaNs tractats amb KNNImputer (Age) i most_frequent (Embarked)\n",
            "   2. Feature engineering: Title, Cabin_known, Family_size, Is_alone\n",
            "   3. Normalitzaci√≥ amb StandardScaler per variables num√®riques\n",
            "   4. OneHotEncoder per variables categ√≤riques\n",
            "   5. No s'aplica PCA (dataset petit, volem interpretabilitat)\n",
            "   6. Mantenim totes les features rellevants (no fem selecci√≥ agressiva)\n",
            "\n",
            "‚úÖ DATASET FINAL:\n",
            "   Samples: 712 train + 179 test = 891 total\n",
            "   Features: 16 (despr√©s del preprocessing)\n",
            "   NaNs: 0 (tots imputats)\n",
            "   Normalitzat: S√≠ (variables num√®riques)\n",
            "   Codificat: S√≠ (variables categ√≤riques)\n",
            "\n",
            "‚úÖ READY FOR MODEL TRAINING! üöÄ\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#===================================================================================\n",
        "# APARTAT 2: PREPROCESSING (2 punts)\n",
        "#===================================================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"APARTAT 2: PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# -------------------------\n",
        "# 2.1 An√†lisi de NaNs\n",
        "# -------------------------\n",
        "print(\"\\nüìä 2.1 AN√ÄLISI DE VALORS FALTANTS\")\n",
        "print(\"-\" * 40)\n",
        "nan_info = pd.DataFrame({\n",
        "    'Total_NaN': df.isna().sum(),\n",
        "    'Percentatge': (df.isna().sum() / len(df) * 100).round(2)\n",
        "})\n",
        "print(nan_info[nan_info['Total_NaN'] > 0])\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  ESTRAT√àGIA DE TRACTAMENT DE NaNs:\")\n",
        "print(\"\\n1. Age (19.87% NaNs):\")\n",
        "print(\"   ‚Üí Estrat√®gia: KNNImputer amb k=5\")\n",
        "print(\"   ‚Üí Justificaci√≥: L'edat √©s una variable cr√≠tica per la superviv√®ncia.\")\n",
        "print(\"     KNNImputer utilitza la informaci√≥ multivariable (Sex, Pclass, Fare, etc.)\")\n",
        "print(\"     per estimar valors m√©s realistes que una simple mitjana.\")\n",
        "print(\"     Mantenim la variabilitat natural i les relacions amb altres variables.\")\n",
        "\n",
        "print(\"\\n2. Cabin (77.10% NaNs):\")\n",
        "print(\"   ‚Üí Estrat√®gia: Crear variable bin√†ria 'Cabin_known' + eliminar columna original\")\n",
        "print(\"   ‚Üí Justificaci√≥: Massa NaNs per imputar de manera fiable.\")\n",
        "print(\"     Tenir cabina coneguda pot indicar classe social o proximitat a les sortides.\")\n",
        "print(\"     La informaci√≥ bin√†ria (t√©/no t√© cabina) √©s m√©s √∫til que la cabina espec√≠fica.\")\n",
        "\n",
        "print(\"\\n3. Embarked (0.22% NaNs):\")\n",
        "print(\"   ‚Üí Estrat√®gia: SimpleImputer amb strategy='most_frequent'\")\n",
        "print(\"   ‚Üí Justificaci√≥: Percentatge m√≠nim de NaNs. La moda √©s suficient i no\")\n",
        "print(\"     distorsiona la distribuci√≥. √âs eficient i mant√© la consist√®ncia.\")\n",
        "\n",
        "print(\"\\nüîç ALTERNATIVES CONSIDERADES I DESCARTADES:\")\n",
        "print(\"\\n‚Ä¢ SimpleImputer (mean/median/mode):\")\n",
        "print(\"  ‚úó Per Age: No considera relacions amb altres variables (Sex, Pclass, etc.)\")\n",
        "print(\"  ‚úì Per Embarked: Adequat pel baix % de NaNs\")\n",
        "\n",
        "print(\"\\n‚Ä¢ IterativeImputer (MICE):\")\n",
        "print(\"  ‚úó Massa computacionalment cost√≥s per aquest dataset\")\n",
        "print(\"  ‚úó Risc de sobreajust amb poques dades\")\n",
        "print(\"  ‚úó KNNImputer ja captura relacions multivariables de forma m√©s simple\")\n",
        "\n",
        "print(\"\\n‚Ä¢ Eliminar files amb NaNs:\")\n",
        "print(\"  ‚úó Perdr√≠em ~20% del dataset (177 passatgers)\")\n",
        "print(\"  ‚úó P√®rdua significativa d'informaci√≥ per entrenar el model\")\n",
        "\n",
        "print(\"\\n‚Ä¢ MissingIndicator:\")\n",
        "print(\"  ‚úó Redundant: ja creem 'Cabin_known' per capturar aquesta informaci√≥\")\n",
        "\n",
        "print(\"\\n‚úì CONCLUSI√ì: KNNImputer per Age + Cabin_known + most_frequent per Embarked\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.2 Feature Engineering\n",
        "# -------------------------\n",
        "print(\"\\nüîß 2.2 FEATURE ENGINEERING\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# 2.2.1 Extreure t√≠tol del nom\n",
        "print(\"\\nüìå 2.2.1 EXTRACCI√ì DE T√çTOL DEL NOM\")\n",
        "df['Title'] = df['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
        "print(f\"T√≠tols √∫nics trobats: {df['Title'].nunique()}\")\n",
        "print(f\"\\nDistribuci√≥ original de t√≠tols:\")\n",
        "print(df['Title'].value_counts())\n",
        "\n",
        "# Agrupar t√≠tols poc freq√ºents\n",
        "title_mapping = {\n",
        "    'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs',\n",
        "    'Lady': 'Mrs', 'Countess': 'Mrs', 'Dona': 'Mrs',\n",
        "    'Capt': 'Officer', 'Col': 'Officer', 'Major': 'Officer',\n",
        "    'Dr': 'Officer', 'Rev': 'Officer', 'Don': 'Officer',\n",
        "    'Sir': 'Officer', 'Jonkheer': 'Officer'\n",
        "}\n",
        "df['Title'] = df['Title'].replace(title_mapping)\n",
        "\n",
        "print(\"\\n‚úì T√≠tols agrupats:\")\n",
        "print(df['Title'].value_counts())\n",
        "print(\"\\nL√≤gica d'agrupaci√≥:\")\n",
        "print(\"  ‚Ä¢ Miss: Dones joves/solteres (Miss, Mlle, Ms)\")\n",
        "print(\"  ‚Ä¢ Mrs: Dones casades/classe alta (Mrs, Mme, Lady, Countess, Dona)\")\n",
        "print(\"  ‚Ä¢ Officer: Homes amb t√≠tols oficials/militars/aristocr√†tics\")\n",
        "print(\"  ‚Ä¢ Mr, Master: Mantinguts per alta freq√º√®ncia i rellev√†ncia\")\n",
        "\n",
        "# 2.2.2 Variable de cabina coneguda\n",
        "print(\"\\nüìå 2.2.2 CREACI√ì DE CABIN_KNOWN\")\n",
        "df['Cabin_known'] = df['Cabin'].notna().astype(int)\n",
        "print(f\"‚úì {df['Cabin_known'].sum()} passatgers ({df['Cabin_known'].mean()*100:.2f}%) amb cabina coneguda\")\n",
        "print(\"   Justificaci√≥: Tenir cabina pot correlacionar amb classe social i superviv√®ncia\")\n",
        "\n",
        "# 2.2.3 Mida de fam√≠lia\n",
        "print(\"\\nüìå 2.2.3 CREACI√ì DE FAMILY_SIZE\")\n",
        "df['Family_size'] = df['SibSp'] + df['Parch'] + 1\n",
        "print(f\"‚úì Rang de Family_size: [{df['Family_size'].min()}, {df['Family_size'].max()}]\")\n",
        "print(f\"   Distribuci√≥: {df['Family_size'].value_counts().sort_index().to_dict()}\")\n",
        "print(\"   Justificaci√≥: Fam√≠lies grans poden tenir m√©s dificultat per evacuar\")\n",
        "\n",
        "# 2.2.4 Viatja sol\n",
        "print(\"\\nüìå 2.2.4 CREACI√ì DE IS_ALONE\")\n",
        "df['Is_alone'] = (df['Family_size'] == 1).astype(int)\n",
        "print(f\"‚úì {df['Is_alone'].sum()} passatgers ({df['Is_alone'].mean()*100:.2f}%) viatjant sols\")\n",
        "print(\"   Justificaci√≥: Viatjar sol pot afectar les possibilitats de superviv√®ncia\")\n",
        "\n",
        "# 2.2.5 Discussi√≥ sobre selecci√≥ de features\n",
        "print(\"\\nüìå 2.2.5 SELECCI√ì DE FEATURES - AN√ÄLISI\")\n",
        "print(\"\\nüîç ENFOCAMENT: Mantenir totes les variables (excepte les eliminades expl√≠citament)\")\n",
        "print(\"\\nRAONAMENT:\")\n",
        "print(\"  ‚Ä¢ En ML no necessitem causalitat, sin√≥ CORRELACI√ì/ASSOCIACI√ì\")\n",
        "print(\"  ‚Ä¢ Prioritzem ACCURACY sobre efici√®ncia computacional\")\n",
        "print(\"  ‚Ä¢ Sense con√®ixer la naturalesa exacta de totes les dades, √©s arriscat eliminar-les\")\n",
        "print(\"\\n‚úì Variables mantingudes: Pclass, Sex, Age, SibSp, Parch, Fare, Embarked,\")\n",
        "print(\"                          Title, Cabin_known, Family_size, Is_alone\")\n",
        "print(\"\\n‚úó Variables eliminades: PassengerId (identificador √∫nic sense valor predictiu)\")\n",
        "print(\"                        Name (informaci√≥ extreta en 'Title')\")\n",
        "print(\"                        Ticket (format inconsistent, dif√≠cil d'interpretar)\")\n",
        "print(\"                        Cabin (substitu√Øda per 'Cabin_known')\")\n",
        "\n",
        "print(\"\\nüìä T√àCNIQUES DE SELECCI√ì CONSIDERADES:\")\n",
        "print(\"\\n‚Ä¢ Mutual Information: Relaci√≥ general entre features i target\")\n",
        "print(\"‚Ä¢ Chi-quadrat / Cram√©r's V: Per variables categ√≤riques\")\n",
        "print(\"‚Ä¢ Point-biserial correlation: Per variables bin√†ries\")\n",
        "print(\"‚Ä¢ Spearman correlation: Per variables ordinals\")\n",
        "print(\"\\n‚ö†Ô∏è  NO APLICADES en aquesta fase perqu√®:\")\n",
        "print(\"   1. Alguns models (Random Forest, XGBoost) fan selecci√≥ impl√≠cita\")\n",
        "print(\"   2. Volem comparar el rendiment amb/sense totes les features\")\n",
        "print(\"   3. El cost computacional √©s acceptable amb aquest dataset\")\n",
        "\n",
        "print(\"\\nüí° MILLORA FUTURA:\")\n",
        "print(\"   Avaluar la import√†ncia de cada feature en el model final (feature_importances_)\")\n",
        "print(\"   i eliminar aquelles amb contribuci√≥ m√≠nima, comparant l'accuracy resultant.\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.3 Eliminaci√≥ de columnes\n",
        "# -------------------------\n",
        "print(\"\\nüóëÔ∏è  2.3 ELIMINACI√ì DE COLUMNES IRRELLEVANTS\")\n",
        "print(\"-\" * 40)\n",
        "cols_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
        "print(f\"Columnes eliminades: {cols_to_drop}\")\n",
        "print(\"\\nJustificacions:\")\n",
        "print(\"  ‚Ä¢ PassengerId: Identificador √∫nic sense valor predictiu\")\n",
        "print(\"  ‚Ä¢ Name: Informaci√≥ extreta en 'Title'\")\n",
        "print(\"  ‚Ä¢ Ticket: Format inconsistent i dif√≠cil d'interpretar\")\n",
        "print(\"  ‚Ä¢ Cabin: Substitu√Øda per 'Cabin_known'\")\n",
        "\n",
        "df_clean = df.drop(columns=cols_to_drop)\n",
        "print(f\"\\n‚úì Dataset resultant: {df_clean.shape}\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.4 Separaci√≥ de features i target\n",
        "# -------------------------\n",
        "print(\"\\nüéØ 2.4 SEPARACI√ì DE FEATURES I TARGET\")\n",
        "print(\"-\" * 40)\n",
        "X = df_clean.drop('Survived', axis=1)\n",
        "y = df_clean['Survived']\n",
        "print(f\"‚úì Features (X): {X.shape}\")\n",
        "print(f\"‚úì Target (y): {y.shape}\")\n",
        "print(f\"\\n‚úì Distribuci√≥ del target:\")\n",
        "distribucio = y.value_counts(normalize=True)\n",
        "for classe, percentatge in distribucio.items():\n",
        "    print(f\"   Classe {classe}: {percentatge:.2%}\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.5 Identificaci√≥ de tipus de variables\n",
        "# -------------------------\n",
        "print(\"\\nüìã 2.5 IDENTIFICACI√ì DE TIPUS DE VARIABLES\")\n",
        "print(\"-\" * 40)\n",
        "numerical_features = ['Age', 'Fare', 'SibSp', 'Parch', 'Family_size']\n",
        "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title']\n",
        "binary_features = ['Cabin_known', 'Is_alone']\n",
        "\n",
        "print(f\"\\nüìä Variables num√®riques ({len(numerical_features)}):\")\n",
        "print(f\"   {numerical_features}\")\n",
        "print(f\"\\nüè∑Ô∏è  Variables categ√≤riques ({len(categorical_features)}):\")\n",
        "print(f\"   {categorical_features}\")\n",
        "print(f\"\\n‚ö´‚ö™ Variables bin√†ries ({len(binary_features)}):\")\n",
        "print(f\"   {binary_features}\")\n",
        "\n",
        "print(\"\\nüí° ESTRAT√àGIA DE CODIFICACI√ì:\")\n",
        "print(\"  ‚Ä¢ Num√®riques: StandardScaler (despr√©s d'imputar NaNs)\")\n",
        "print(\"  ‚Ä¢ Categ√≤riques: OneHotEncoder amb drop='first' (evitar multicolinearitat)\")\n",
        "print(\"  ‚Ä¢ Bin√†ries: Sense transformaci√≥ (ja s√≥n 0/1)\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.6 An√†lisi de normalitzaci√≥\n",
        "# -------------------------\n",
        "print(\"\\nüìê 2.6 AN√ÄLISI DE NORMALITZACI√ì\")\n",
        "print(\"-\" * 40)\n",
        "print(\"\\n‚ùì ESTAN LES DADES NORMALITZADES?\")\n",
        "print(\"\\nEstad√≠stiques ABANS de normalitzar:\")\n",
        "stats_before = X[numerical_features].describe().loc[['mean', 'std', 'min', 'max']]\n",
        "print(stats_before)\n",
        "\n",
        "print(\"\\n‚ùå NO estan normalitzades:\")\n",
        "print(f\"   ‚Ä¢ Age: rang [0.42, 80] amb mean‚âà{X['Age'].mean():.1f}\")\n",
        "print(f\"   ‚Ä¢ Fare: rang [0, 512] amb mean‚âà{X['Fare'].mean():.1f}\")\n",
        "print(f\"   ‚Ä¢ Les escales s√≥n molt diferents ‚Üí Afecta models basats en dist√†ncies\")\n",
        "\n",
        "print(\"\\n‚úÖ CALDRIA NORMALITZAR-LES?\")\n",
        "print(\"\\n   S√ç, pels seg√ºents motius:\")\n",
        "print(\"   1. Models sensibles a escales (KNN, SVM, Regressi√≥ Log√≠stica):\")\n",
        "print(\"      ‚Üí Fare (0-512) dominaria sobre Age (0-80) en c√†lculs de dist√†ncia\")\n",
        "print(\"   2. Millora la converg√®ncia de gradient descent\")\n",
        "print(\"   3. Facilita la interpretaci√≥ de coeficients en models lineals\")\n",
        "print(\"   4. StandardScaler √©s robust a outliers moderats\")\n",
        "\n",
        "print(\"\\nüîß TIPUS DE NORMALITZACI√ì ESCOLLIDA: StandardScaler\")\n",
        "print(\"\\n   F√≥rmula: z = (x - Œº) / œÉ\")\n",
        "print(\"   ‚Ä¢ Transforma a mitjana=0 i std=1\")\n",
        "print(\"   ‚Ä¢ Mant√©n la distribuci√≥ original\")\n",
        "print(\"   ‚Ä¢ No afectat per outliers extrems (a difer√®ncia de MinMaxScaler)\")\n",
        "print(\"\\n   Alternatives considerades:\")\n",
        "print(\"   ‚Ä¢ MinMaxScaler: ‚úó Sensible a outliers (Fare t√© valors extrems)\")\n",
        "print(\"   ‚Ä¢ RobustScaler: ‚úì Alternativa v√†lida (tractament d'outliers), per√≤ StandardScaler √©s suficient\")\n",
        "print(\"   ‚Ä¢ Normalizer: ‚úó Normalitza per files, no per columnes (no aplica aqu√≠)\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.7 Discussi√≥ sobre PCA\n",
        "# -------------------------\n",
        "print(\"\\nüî¨ 2.7 CALDRIA APLICAR PCA?\")\n",
        "print(\"-\" * 40)\n",
        "print(\"\\n‚ùå NO aplicarem PCA en aquest cas\")\n",
        "print(\"\\nRAONS:\")\n",
        "print(\"  ‚Ä¢ Dataset petit (891 passatgers, ~15 features despr√©s de OneHot)\")\n",
        "print(\"  ‚Ä¢ No hi ha problema de dimensionalitat (regla general: n_samples >> n_features)\")\n",
        "print(\"  ‚Ä¢ P√®rdua d'interpretabilitat: no sabr√≠em quines features s√≥n importants\")\n",
        "print(\"  ‚Ä¢ Les features tenen significat real i volem mantenir-lo\")\n",
        "\n",
        "print(\"\\n‚úÖ BENEFICIS de PCA (si s'apliqu√©s):\")\n",
        "print(\"  + Reducci√≥ de dimensionalitat\")\n",
        "print(\"  + Eliminaci√≥ de multicolinearitat\")\n",
        "print(\"  + Reducci√≥ de soroll\")\n",
        "print(\"  + Millora computacional en datasets grans\")\n",
        "\n",
        "print(\"\\n‚ùå INCONVENIENTS de PCA:\")\n",
        "print(\"  - P√®rdua d'interpretabilitat (components principals no tenen significat clar)\")\n",
        "print(\"  - Assumeix relacions lineals\")\n",
        "print(\"  - Requereix normalitzaci√≥ pr√®via\")\n",
        "print(\"  - Pot eliminar informaci√≥ rellevant per models no lineals\")\n",
        "\n",
        "print(\"\\nüí° CONCLUSI√ì: Mantenim les features originals per interpretabilitat i\")\n",
        "print(\"              perqu√® el dataset no t√© problemes de dimensionalitat.\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.8 Pipeline de preprocessing\n",
        "# -------------------------\n",
        "print(\"\\nüîÑ 2.8 CREACI√ì DEL PIPELINE DE PREPROCESSING\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Pipeline per variables num√®riques: KNNImputer + StandardScaler\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', KNNImputer(n_neighbors=5)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline per variables categ√≤riques: SimpleImputer + OneHotEncoder\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# ColumnTransformer per combinar tots els transformadors\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'  # Variables bin√†ries sense transformar\n",
        ")\n",
        "\n",
        "print(\"‚úì Pipeline creat amb 3 components:\")\n",
        "print(\"\\n  1Ô∏è‚É£  NUM√àRIQUES:\")\n",
        "print(\"      ‚Üí KNNImputer(n_neighbors=5): Imputa Age basant-se en 5 ve√Øns m√©s propers\")\n",
        "print(\"      ‚Üí StandardScaler(): Normalitza a mean=0, std=1\")\n",
        "print(f\"      ‚Üí Aplica a: {numerical_features}\")\n",
        "\n",
        "print(\"\\n  2Ô∏è‚É£  CATEG√íRIQUES:\")\n",
        "print(\"      ‚Üí SimpleImputer(most_frequent): Imputa Embarked amb la moda\")\n",
        "print(\"      ‚Üí OneHotEncoder(drop='first'): Evita dummy variable trap\")\n",
        "print(f\"      ‚Üí Aplica a: {categorical_features}\")\n",
        "\n",
        "print(\"\\n  3Ô∏è‚É£  BIN√ÄRIES:\")\n",
        "print(\"      ‚Üí Passthrough: No es transformen (ja s√≥n 0/1)\")\n",
        "print(f\"      ‚Üí Aplica a: {binary_features}\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.9 Split i aplicaci√≥ del preprocessing\n",
        "# -------------------------\n",
        "print(\"\\n‚öôÔ∏è  2.9 TRAIN/TEST SPLIT I APLICACI√ì DEL PREPROCESSING\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Split ABANS del preprocessing per evitar data leakage\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"‚úì Train set: {X_train.shape} ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"‚úì Test set:  {X_test.shape} ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\n‚úì Distribuci√≥ mantinguda (stratify=y):\")\n",
        "dist_train = y_train.value_counts(normalize=True)\n",
        "dist_test = y_test.value_counts(normalize=True)\n",
        "for classe in [0, 1]:\n",
        "    print(f\"   Classe {classe}: Train={dist_train[classe]:.2%}, Test={dist_test[classe]:.2%}\")\n",
        "\n",
        "# Aplicar preprocessing\n",
        "print(\"\\nüîß Aplicant preprocessing...\")\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "\n",
        "print(f\"\\n‚úì Dades preprocessades:\")\n",
        "print(f\"   Train shape: {X_train_preprocessed.shape}\")\n",
        "print(f\"   Test shape:  {X_test_preprocessed.shape}\")\n",
        "print(f\"   Total features: {X_train_preprocessed.shape[1]}\")\n",
        "\n",
        "# Verificar normalitzaci√≥\n",
        "n_numeric = len(numerical_features)\n",
        "sample_numeric = X_train_preprocessed[:, :n_numeric]\n",
        "print(f\"\\n‚úÖ VERIFICACI√ì DE NORMALITZACI√ì (primeres {n_numeric} columnes num√®riques):\")\n",
        "print(f\"   Mitjana:     {sample_numeric.mean():.6f} (esperat: ‚âà0)\")\n",
        "print(f\"   Desv. std:   {sample_numeric.std():.6f} (esperat: ‚âà1)\")\n",
        "print(f\"   Min:         {sample_numeric.min():.2f}\")\n",
        "print(f\"   Max:         {sample_numeric.max():.2f}\")\n",
        "\n",
        "if abs(sample_numeric.mean()) < 0.01 and abs(sample_numeric.std() - 1) < 0.1:\n",
        "    print(\"\\n   ‚úì Normalitzaci√≥ correcta!\")\n",
        "else:\n",
        "    print(\"\\n   ‚ö†Ô∏è  Possible problema amb la normalitzaci√≥\")\n",
        "\n",
        "# -------------------------\n",
        "# 2.10 Resum final\n",
        "# -------------------------\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìù RESUM DEL PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n‚úÖ DECISIONS PRESES:\")\n",
        "print(\"   1. NaNs tractats amb KNNImputer (Age) i most_frequent (Embarked)\")\n",
        "print(\"   2. Feature engineering: Title, Cabin_known, Family_size, Is_alone\")\n",
        "print(\"   3. Normalitzaci√≥ amb StandardScaler per variables num√®riques\")\n",
        "print(\"   4. OneHotEncoder per variables categ√≤riques\")\n",
        "print(\"   5. No s'aplica PCA (dataset petit, volem interpretabilitat)\")\n",
        "print(\"   6. Mantenim totes les features rellevants (no fem selecci√≥ agressiva)\")\n",
        "print(\"\\n‚úÖ DATASET FINAL:\")\n",
        "print(f\"   Samples: {len(X_train)} train + {len(X_test)} test = {len(X)} total\")\n",
        "print(f\"   Features: {X_train_preprocessed.shape[1]} (despr√©s del preprocessing)\")\n",
        "print(f\"   NaNs: 0 (tots imputats)\")\n",
        "print(f\"   Normalitzat: S√≠ (variables num√®riques)\")\n",
        "print(f\"   Codificat: S√≠ (variables categ√≤riques)\")\n",
        "print(\"\\n‚úÖ READY FOR MODEL TRAINING! üöÄ\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axc-wn2rCl7T"
      },
      "source": [
        "### 3. Metric selection (1.5 punts)\n",
        "En aquest apartat ens centrarem en les m√®triques de classificaci√≥ ([documentaci√≥](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)). Per a fer-ho, entreneu una regressio logistica i a partir d'aquesta generarem una serie de funcions per analitzar els nostres resultats. Aquestes funcions ens serviran m√©s endavant. Caldr√† tambe triar la m√®trica que farem servir despr√©s per triar el millor model.\n",
        "\n",
        "**Preguntes:**\n",
        "* A teoria, hem vist el resultat d'aplicar el `accuracy_score` sobre dades no balancejades. Podrieu explicar i justificar quina de les seg√ºents m√®triques ser√° la m√©s adient pel vostre problema? `accuracy_score`, `f1_score` o `average_precision_score`?\n",
        "* Abans de comen√ßar a entrenar models, genereu una suite de funcions per poder analitzar graficament com esta anant el vostre model. Mostreu la Precisi√≥-Recall Curve i la ROC Curve. Quina √©s m√©s rellevant pel vostre dataset?\n",
        "* Qu√® mostra [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)? Quina m√®trica us fixareu per tal de optimitzar-ne la classificaci√≥ pel vostre cas?\n",
        "\n",
        "**Nota**: Fixeu-vos que en aquest apartat NO ES VALOREN ELS RESULTATS. L'√∫nic que es valora √©s l'elecci√≥ de la m√®trica de classificaci√≥ aix√≠ com saber quin tipus de gr√†fiques fer per analitzar els resultats. Abans de solucionar un problema cal tenir molt clar la m√®trica d'error que es far√† servir, i √©s una decisi√≥ que cal pendre de forma pr√®via a entrenar models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8xe5r78Cl7T"
      },
      "source": [
        "### 4. Model Selection amb validaci√≥ creuada (4 punts)\n",
        "\n",
        "Fent servir la m√®trica trobada en l'apartat anterior, en aquest apartat caldr√† seleccionar una s√®rie de models i, fent √∫s de la validaci√≥ creuada, seleccionar el millor model amb els seus respectius millors hyperp√†rametres que haurem buscat fent hyperparameter search.\n",
        "\n",
        "La tasca d'aquesta pr√†ctica s'enmarca dins l'aprenentatge computacional **supervisat**. A sklearn, disposem de diverses t√®cniques [(veure documentaci√≥)](https://scikit-learn.org/stable/supervised_learning.html). A les classes de teoria, hem vist t√®cniques com ara logistic regression, SVM amb diferents kernels, Nearest Neighbour... i tamb√© coneixeu altres tecniques d'altres cursos, com els arbres de decisio. Per aquest apartat es demana seleccionar **un minim de 3 models**.\n",
        "\n",
        "**Preguntes:**\n",
        "* Quins models heu considerat? Per qu√® els heu seleccionat?\n",
        "* Fent servir validaci√≥ creuada, escolliu el millor model (agafant els hiperpar√†metres per defecte). Recordeu fer servir la m√®trica utilitzada en l'apartat anterior i fer fer servir algun [tipus de validacio creuada](https://scikit-learn.org/stable/modules/cross_validation.html).\n",
        "\n",
        "* Seleccioneu una s√®rie d'hiperpar√†metres a provar per cadascun dels models i realitzeu una cerca d'hiperpar√†metres. Hi ha algun model que creieu que podeu descartar de primeres? Per qu√®?\n",
        "\n",
        "* Mostreu els resultats en una taula on es mostri el model, els experiments realitzats i els resultats obtinguts (tant en train com en test). Podeu mostrar tambe el temps d'entrenament de cada model.\n",
        "\n",
        "* Quin tipus de validaci√≥ heu escollit en la selecci√≥ de models?\n",
        "\n",
        "* Quines formes de buscar els millors hiperpar√†metres heu trobat? S√≥n costoses computacionalment parlant? [documentaci√≥](https://scikit-learn.org/stable/modules/grid_search.html). Quina heu seleccionat?\n",
        "\n",
        "* Si disposem de recursos limitats (per exemple, un PC durant 1 hora), quin dels m√®todes creieu que obtindr√† millor resultat final?\n",
        "\n",
        "* Opcional: Feu la prova, i amb el model i el metode de validaci√≥ creuada escollit, configureu els diferents m√®todes de cerca per a que s'executin durant el mateix temps (i.e. depenent del problema, 0,5h-1 hora). Analitzeu quin ha arribat a una millor soluci√≥. (Ajuda: estimeu el temps que trigar√† a fer 1 training el vostre model, i aix√≠ trobeu el n√∫mero de intents que podeu fer en cada cas.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx-3b7v2TwJ3"
      },
      "source": [
        "### 5.An√†lisi Final (1.5 punt)\n",
        "\n",
        "Un cop seleccionat el millor model amb els millors hiperpar√†metres, caldr√† fer un an√†lisi final amb els resultats obtinguts.\n",
        "\n",
        "**Preguntes:**\n",
        "* Mostreu les corves ROC/PR (la que hagueu escollit en l'apartat 2) i interpreteu els resultats.\n",
        "\n",
        "* Analitzeu en detall les diferents m√®triques que trobeu adients i comenteu per sobre com podrieu fer servir aquest model en un futur. Aix√≤ √©s el que es coneix com un cas d'√∫s.\n",
        "\n",
        "* Com creieu que es podria millorar el vostre model?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
